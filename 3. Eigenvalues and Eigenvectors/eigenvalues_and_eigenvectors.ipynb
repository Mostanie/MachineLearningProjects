{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7ead65-3041-40e6-96ad-f86eefff769f",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:35px\">ÖZDEĞERLER VE ÖZVEKTÖRLER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b53a7-7da6-4c7f-ab41-d5dca719c159",
   "metadata": {},
   "source": [
    "<span style=\"color: red;font-size:15px\">Kaynakça: </span><span style=\"font-size:15px\">https://machinelearningmastery.com/introduction-to-eigendecomposition-eigenvalues-and-eigenvectors/</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a24be0d-a28b-40c1-98b5-6805a2abdd75",
   "metadata": {},
   "source": [
    "<span style=\"font-size:15px\">Matris ayrıştırmaları, bir matrisin kendini temsil eden daha küçük ve anlamlı parçalara ayrılabilmesini sağlayarakkarmaşık işlemleri basitleştirmek için kullanılan yararlı bir araçtır.<br>\n",
    "Belki de en yaygın kullanılan matris ayrıştırma türü, bir matrisi özvektörlere (eigenvector) ve özdeğerlere (eigenvalue) ayıran öz ayrıştırmadır (eigendecomposition). Bu ayrıştırma, Temel Bileşenler Analizi (Principal Component Analysis - PCA) gibi makine öğrenmesinde kullanılan yöntemlerde de önemli bir rol oynar.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b601b3-c936-4bce-a2b2-1ca110513e6d",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px\">Matrisleri Öz Ayrıştırma İşlemi (Eigendecomposition of a Matrix)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b6a88-19fd-411b-b932-86577315c180",
   "metadata": {},
   "source": [
    "<span style=\"font-size:15px\">Bir matrisin öz ayrıştırma işlemi bir kare matrisin özvektör ve özdeğerlere ayrışımı işlemidir.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0777af55-dad3-4577-a12b-f9dc47232407",
   "metadata": {},
   "source": [
    "<span style=\"font-size:15px\">Bir vektörün, bir matrisin özvektörü olabilmesi için A . v = lambda . v bu eşitliğin sağlanması şarttır.\n",
    "<br>Bu eşitliğe özvektör eşitliği denir. Buradaki A parçalamak istediğimiz kare matrisi temsil eder, v A matrisinin özvektörü olur ve lambda özdeğeri temsil eder. <br>Ana matris özvektör ve özdeğerlerin çarpımı olarak tekrar üretilebilir. Bu üretim için A = Q . diag(V) . Q⁻¹ eşitliği kullanılır.<br>\n",
    "Buradaki Q özvektörlerden oluşan matrisimizdir. Diag(V), özdeğerlerin köşegen üzerinde yer aldığı köşegen bir matristir. Q⁻¹ ise özvektörlerden oluşan matrisin tersidir. \n",
    "Q, özvektörlerden oluşan bir matristir; diag(V), özdeğerlerin köşegen üzerinde yer aldığı bir köşegen matristir (bazen büyük lambda harfiyle temsil edilir); ve Q⁻¹, özvektörlerden oluşan matrisin tersidir. \n",
    "    </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfd0a1-be0f-42bd-9ac1-c972cbe7fa5c",
   "metadata": {},
   "source": [
    "<span style=\"font-size:15px\">Biraz da eigendecomposition'un makine öğrenmesindeki rolüne bakalım. Eigendecomposition Principal Component Analysis (PCA) yönteminde bir matrisin ana bileşenlerini hesaplamak için de kullanılabilir. PCA, makine öğrenmesinde verilerin boyutunu azaltmak için kullanılan bir tekniktir.<br>PCA, veriyi daha düşük boyutlu bir alana indirgemek için kullanılan güçlü bir tekniktir. Bu teknik, genellikle verinin çeşitliliğini en iyi şekilde temsil eden özellikleri (principal components) bulur ve bu özellikleri kullanarak veriyi daha az boyutla ifade eder. PCA, özdeğerler (eigenvalues) ve özvektörler (eigenvectors) kullanarak bu boyut indirgemeyi sağlar ve bu işlem Eigendecomposition olarak bilinir. Bu notebookun sonunda PCA algoritmasının çalışma mantığına detaylıca bakılacaktır.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dadb530-1610-4fc9-bbd8-a8851a40094b",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px\">Özdeğerler ve Özvektörler</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591cc90f-c4ca-4854-9dd3-3cdb8a15f90e",
   "metadata": {},
   "source": [
    "<span style=\"font-size:15px\">Özvektörler birim vektörlerdir yani büyüklükleri 1 değerine eşit olur. Ayrıca sağ vektörler (right vectors) olarak da adlandırılırlar. Burada sağ vektör, vektörün sütun (column) formunda olduğunu belirtir.<br><br>\n",
    "Özdeğerler, özvektörlere uygulanan çarpanlar (koefisiyentler) olarak düşünülebilir. Bu çarpanlar, özvektörlerin uzunluklarını (büyüklüklerini) değiştiren faktörlerdir.<br>\n",
    "Eğer negatif bir özdeğer özvektörlerle işleme girerse bu işlem özvektörü ölçeklendirirken yön değiştirmesine neden olabilir.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579cbbe9-dbb2-4d1e-9c6f-be7b6a451815",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px\">Öz Ayrıştırma İşlemleri</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0ab1f-ef0f-4536-a57d-2e95d9dd8e3a",
   "metadata": {},
   "source": [
    "<span style=\"font-size:15px\">Bir kare matrisin özdeğer-ayrışımı (eigendecomposition), verimli bir yinelemeli algoritmayla hesaplanabilir. Genellikle önce bir özdeğer bulunur, ardından bu özdeğere karşılık gelen özvektör elde edilir. NumPy'de bu işlem eig() fonksiyonu ile yapılabilir. Aşağıdaki örnekte, 3×3 boyutunda bir matris tanımlanır ve özdeğer-ayrışımı yapılarak özdeğerler ve özvektörler elde edilir.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b5a53f-a3d7-44ab-a7f3-2fa0d2ae57ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "Values =  [ 1.61168440e+01 -1.11684397e+00 -3.38433605e-16]\n",
      "\n",
      "Vectors =  [[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy.linalg import eig\n",
    "\n",
    "A = array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"A = \\n\",A)\n",
    "\n",
    "values, vectors = eig(A)\n",
    "print(\"\\nValues = \",values)\n",
    "print(\"\\nVectors = \",vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51656a9-6bda-46d7-8c2e-1ae47d1567df",
   "metadata": {},
   "source": [
    "<br><span style=\"color:red; font-size:20px\">Özvektör Doğrulaması</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820c8db-f642-4fc8-8099-3e2b6f95d088",
   "metadata": {},
   "source": [
    "<span style=\"font-size:15px\">Bir vektörün bir matrisin özvektörü olup olmadığını şöyle doğrularız:<br>\n",
    "Aday özvektörü matrisle çarparız ve sonucu özdeğer ile aday özvektörün çarpımıyla karşılaştırırız. Değerler aynı çıkarsa aday özvektörümüz gerçek özvektörümüzdür.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16dabe02-f5bd-472f-aa59-ffc5e8345777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B =  [ -3.73863537  -8.46653421 -13.19443305]\n",
      "\n",
      "C =  [ -3.73863537  -8.46653421 -13.19443305]\n"
     ]
    }
   ],
   "source": [
    "A = array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "values, vectors = eig(A)\n",
    "\n",
    "B = A.dot(vectors[:, 0])\n",
    "print(\"B = \",B)\n",
    "C = vectors[:, 0] * values[0]\n",
    "print(\"\\nC = \",C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea5928-5f09-4537-bc52-dd9fc1044227",
   "metadata": {},
   "source": [
    "<br><span style=\"color:red; font-size:20px\">Orijinal Matrisin Tekrar Elde Edilmesi</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c9a46-13c8-4be1-9244-63fcf1a311d8",
   "metadata": {},
   "source": [
    "<span style=\"font-size:15px\">İzlenilen adımları tersten izleyerek bir matrisi onun özdeğerlerinden ve özvektörlerinden elde edebiliriz.<br>\n",
    "Öncelikle özvektörler bir matrise dönüştürülmelidir, burada her bir vektör bir satır haline gelir. Özdeğerler ise köşegen (diyagonal) bir matrise yerleştirilmelidir. Bunun için NumPy'nin diag() fonksiyonu kullanılabilir.<br>\n",
    "Sonrasında özvektör matrisinin tersini almamız gerekir, bunu da NumPy'nin inv() fonksiyonu ile gerçekleştirebiliriz. Son olarak, bu elemanların hepsi dot() fonksiyonu ile birbiriyle çarpılmalıdır.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4adedd5-6d12-46a8-bcca-54fc42f7f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A =  [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "B =\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import diag\n",
    "from numpy import dot\n",
    "from numpy.linalg import inv\n",
    "A = array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\nA = \",A)\n",
    "\n",
    "values, vectors = eig(A)\n",
    "\n",
    "Q = vectors\n",
    "\n",
    "R = inv(Q)\n",
    "\n",
    "L = diag(values)\n",
    "\n",
    "B = Q.dot(L).dot(R)\n",
    "print(\"\\nB =\\n\",B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a94d1-01a6-4118-94a1-3ca4ecbc1e52",
   "metadata": {},
   "source": [
    "<br><span style=\"font-size:20px\">Bu notebookda ayrıca PCA algoritmasını da değineceğiz.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83371f-2bdd-43ca-a72a-b3cc5a8c7792",
   "metadata": {},
   "source": [
    "<br><span style=\"color: red;font-size:20px\">Principal Component Analysis (Temel Bileşen Analizi)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94862467-644a-4a12-ab08-bf1f479851e1",
   "metadata": {},
   "source": [
    "<span style=\"color: red;font-size:15px\">Kaynakça: https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/</span>\n",
    "<br><span style=\"font-size:15px\">Temel Bileşen Analizi ya da kısaca PCA (Principal Component Analysis), verinin boyutunu azaltmak için kullanılan bir yöntemdir. Bu yöntem, m sütunlu (özellikli) verinin, m veya daha az sütunlu bir alt uzaya yansıtıldığı bir projeksiyon yöntemi olarak düşünülebilir, bu sırada verinin özünü korunmasına dikkat edilir. PCA yöntemi, lineer cebirin araçları kullanılarak tanımlanabilir ve uygulanabilir.<br>PCA, n x m boyutlarında bir A veri matrisi üzerinde uygulanan bir işlemdir ve bunun sonucunda A'nın bir projeksiyonu olan B matrisi elde edilir. Şimdi bu işlemin adımlarının nasıl yapılacağı konusuna gelelim:\n",
    "<br><br>İlk adım her sütunun ortalama değerini hesaplamaktır.<br>\n",
    "İkinci adımda her sütundaki değerleri merkezlemek için tüm sütun değerlerini ortalama değerden çıkarırız.<br>\n",
    "Sonraki adımda merkezlenmiş olan matrisimizin kovaryans matrisini hesaplarız.(Cov(A) = (1/(n-1))*A(Transpose)*A)<br>\n",
    "Korelasyon, iki sütunun birlikte ne kadar ve hangi yönde (pozitif ya da negatif) değiştiğini gösteren normalize edilmiş bir ölçümdür.<br>\n",
    "Kovaryans ise, korelasyonun daha genelleştirilmiş ve normalize edilmemiş hâlidir ve birden fazla sütun arasında kullanılır.<br>\n",
    "Son olarak kovaryans matrisinin eigendecomposition değerini hesaplarız. Bu işlem, özdeğerler ve özvektörler listelerini elde etmemizi sağlar.<br><br>\n",
    "Özvektörler, B'nin indirgenmiş alt uzayının yönlerini veya bileşenlerini temsil ederken, özdeğerler bu yönlerin büyüklüklerini temsil eder.<br>Özvektörler, özdeğerlerine göre azalan sırayla sıralanarak, A'nın yeni alt uzayının bileşenlerinin veya eksenlerinin bir sıralamasını sağlar.\n",
    "<br>\n",
    "Eğer tüm özdeğerler benzer bir değere sahipse, mevcut temsilin zaten makul derecede sıkıştırılmış veya yoğun olduğunu ve projeksiyonun pek fazla fayda sağlamayabileceğini anlarız. Eğer özdeğerler sıfıra yakınsa, bunlar B'nin atılabilecek bileşenlerini veya eksenlerini temsil eder.\n",
    "<br>\n",
    "Seçilen alt uzayı oluşturmak için toplamda m veya daha az bileşen seçilmelidir. İdeal olarak, en büyük k özdeğerine sahip olan k özvektörü, yani ana bileşenler seçilmelidir.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23da7022-b66d-4a4c-86f4-3e3e9ae32046",
   "metadata": {},
   "source": [
    "<br><span style=\"color: red;font-size:20px\">PCA'yı Manuel Olarak Hesaplamak</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa18f6fe-8dba-4dda-ac13-006cf5e3a2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Mean = [3. 4.]\n",
      "\n",
      "C = \n",
      " [[-2. -2.]\n",
      " [ 0.  0.]\n",
      " [ 2.  2.]]\n",
      "\n",
      "V =\n",
      " [[4. 4.]\n",
      " [4. 4.]]\n",
      "\n",
      "Vectors = \n",
      " [[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "\n",
      "Values = \n",
      " [8. 0.]\n",
      "\n",
      "P.T = \n",
      " [[-2.82842712  0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.82842712  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n",
    "A = array([[1, 2], [3, 4], [5, 6]])\n",
    "print(\"A = \\n\",A)\n",
    "\n",
    "M = mean(A.T, axis=1)\n",
    "print(\"\\nMean =\",M)\n",
    "\n",
    "C = A - M\n",
    "print(\"\\nC = \\n\",C)\n",
    "\n",
    "V = cov(C.T)\n",
    "print(\"\\nV =\\n\",V)\n",
    "\n",
    "values, vectors = eig(V)\n",
    "print(\"\\nVectors = \\n\",vectors)\n",
    "print(\"\\nValues = \\n\",values)\n",
    "\n",
    "P = vectors.T.dot(C.T)\n",
    "print(\"\\nP.T = \\n\",P.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
